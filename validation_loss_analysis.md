# 검증 로스(Validation Loss) 불안정 원인 분석

## 관찰된 현상

터미널 출력을 보면:
- **Train Loss**: 지속적으로 감소 (0.5087 → 0.2541)
- **Val Loss**: 불안정하게 변동 (0.8950 → 1.1797 → 0.8531 → 0.7748 → 1.1013 → 1.7053)

이는 전형적인 **과적합(Overfitting)** 또는 **학습 불안정** 문제입니다.

## 주요 원인 분석

### 1. 데이터 분포 불일치 (Distribution Shift)

**문제점**:
- 시계열 데이터를 시간 순서대로 분할 (shuffle=False)
- Train/Val/Test가 서로 다른 시장 환경을 포함
- 예: Train은 상승장, Val은 하락장 또는 변동성이 다른 구간

**증거**:
- Epoch 1: val_loss = 0.8950 (비교적 양호)
- Epoch 2: val_loss = 1.1797 (급격히 악화)
- Epoch 24: val_loss = 0.7748 (개선)
- Epoch 30: val_loss = 1.7053 (다시 악화)

**왜 발생하나?**
- 180일 데이터에서 시장 환경이 크게 변함
- 비트코인 가격이 107,000~108,000 범위에서 변동
- Train 데이터와 Val 데이터의 가격 분포, 변동성, 트렌드가 다를 수 있음

### 2. 모델 복잡도 vs 데이터 양 불균형

**현재 설정**:
- 모델 파라미터: 약 80만개 (PatchCNN-BiLSTM)
- 학습 데이터: 약 33,000개 (전체의 64%)
- 검증 데이터: 약 8,000개 (전체의 16%)

**문제점**:
- 모델이 너무 복잡해서 작은 검증 세트에 과적합
- 검증 세트가 작아서 통계적으로 불안정
- 배치 크기(64)가 상대적으로 커서 검증 세트의 일부만 평가

### 3. 스케일링 문제

**현재 설정**:
- StandardScaler 사용
- 전체 데이터로 스케일러 학습 후 분할

**잠재적 문제**:
- Train/Val/Test의 분포가 다르면 스케일링이 부적절할 수 있음
- 특히 시계열에서 미래 데이터의 분포가 과거와 다를 수 있음
- Val 데이터가 Train 데이터의 분포 범위를 벗어날 수 있음

### 4. 학습률 및 최적화 문제

**현재 설정**:
- Learning rate: 0.0005 → 0.00025 (ReduceLROnPlateau)
- Optimizer: Adam
- Batch size: 64

**문제점**:
- 학습률이 너무 높아서 검증 세트에서 불안정할 수 있음
- Adam의 적응적 학습률이 검증 세트의 노이즈에 과도하게 반응
- 배치 크기가 커서 gradient가 부정확할 수 있음

### 5. 드롭아웃 부족

**현재 설정**:
- Dropout rate: 0.2

**문제점**:
- 과적합을 방지하기에 부족할 수 있음
- 특히 복잡한 모델에서 더 많은 정규화가 필요

### 6. Early Stopping Patience 부족

**현재 설정**:
- Early stopping patience: 20
- Reduce LR patience: 8

**문제점**:
- Val loss가 불안정하게 변동하는데 patience가 충분하지 않을 수 있음
- 하지만 이미 20으로 설정되어 있어서 이것은 주요 원인이 아닐 수 있음

### 7. 시계열 데이터의 특성

**문제점**:
- 시계열 데이터는 시간에 따라 분포가 변함 (Non-stationary)
- 비트코인 가격은 트렌드, 계절성, 변동성 클러스터링 등이 있음
- Train과 Val이 다른 시장 환경을 보면 모델이 일반화하기 어려움

**증거**:
- Train loss는 계속 감소 (과적합)
- Val loss는 불안정 (일반화 실패)

### 8. 특징 스케일링 문제

**문제점**:
- 38개의 특징이 모두 StandardScaler로 스케일링됨
- 일부 특징(RSI, CCI 등)은 이미 정규화된 값인데 다시 스케일링
- 다른 특징(가격, 거래량)은 절대값이 크고 분포가 다름
- 모든 특징을 동일하게 스케일링하면 정보 손실 가능

## 가장 가능성 높은 원인 순위

1. **데이터 분포 불일치** (Distribution Shift)
   - Train과 Val이 다른 시장 환경
   - 시계열의 Non-stationary 특성
   - 가장 가능성 높음

2. **과적합**
   - 모델이 Train 데이터에 과도하게 적합
   - Val 데이터의 패턴을 학습하지 못함
   - Train loss 감소 vs Val loss 불안정

3. **검증 세트 크기 부족**
   - 약 8,000개로 통계적으로 불안정
   - 작은 변화에도 큰 변동

4. **스케일링 문제**
   - Train/Val 분포 차이
   - 미래 데이터의 분포 변화

5. **학습률 및 최적화**
   - Adam의 적응적 학습률이 불안정
   - 배치 크기와 학습률의 불일치

## 결론

검증 로스가 불안정한 주요 원인은:

1. **시계열 데이터의 분포 변화**: Train과 Val이 서로 다른 시장 환경을 포함
2. **과적합**: 모델이 Train 데이터에 과도하게 적합하여 Val에서 일반화 실패
3. **검증 세트의 통계적 불안정성**: 상대적으로 작은 검증 세트 크기

이 문제는 시계열 예측에서 흔히 발생하는 현상이며, 특히 금융 시계열 데이터에서 더욱 두드러집니다.

